{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport pandas as pd\n\n!pip install openai\n!pip install --upgrade openai\nimport openai\nimport json\napi_key = \"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\"\nopenai.api_key = api_key","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-29T14:33:46.026258Z","iopub.execute_input":"2023-05-29T14:33:46.026681Z","iopub.status.idle":"2023-05-29T14:34:08.734831Z","shell.execute_reply.started":"2023-05-29T14:33:46.026644Z","shell.execute_reply":"2023-05-29T14:34:08.733771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/taiwan-112/112_1301.csv\n/kaggle/input/taiwan-112/112_3302.csv\n/kaggle/input/taiwan-112/112_4302.csv\n/kaggle/input/taiwan-112/112_2301.csv\n/kaggle/input/taiwan-112/112_2302.csv\n/kaggle/input/taiwan-112/112_1302.csv\nCollecting openai\n  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.27.7)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"!rm -rf ./*","metadata":{"execution":{"iopub.status.busy":"2023-05-29T14:33:35.483562Z","iopub.execute_input":"2023-05-29T14:33:35.483943Z","iopub.status.idle":"2023-05-29T14:33:36.529430Z","shell.execute_reply.started":"2023-05-29T14:33:35.483914Z","shell.execute_reply":"2023-05-29T14:33:36.528156Z"}}},{"cell_type":"code","source":"def get_q(year, code, question):\n    file_path = f'/kaggle/input/taiwan-112/{year}_{code}.csv'\n    df = pd.read_csv(file_path)\n    if question > len(df) or question < 1:\n        raise IndexError(f\"Question index out of range. Please enter a value between 1 and {len(df)}.\")\n    nth_question = df.iloc[question - 1, -1]\n    return nth_question\n\ndef gpt_trans(year, code, question, model):\n    if model == 4:\n        model_name = \"gpt-4\"\n    elif model == 3.5:\n        model_name = \"gpt-3.5-turbo\"\n    else:\n        raise ValueError(\"Invalid model value. Must be either 4 or 3.5\")\n    response = openai.ChatCompletion.create(\n        model=model_name,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional medical translator.\"},\n            {\"role\": \"user\", \"content\": f'translate the following question from zh-tw to en-us in proper medical terminology: {get_q(year, code, question)}'}\n        ],\n        max_tokens=1024,\n        temperature=0,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0\n    )\n    return response\n\n\ndef gpt_trans_loop(year, code, q_start, q_fin, model):\n    data = {\n        'year': [],\n        'code': [],\n        'question_no': [],\n        'id': [],\n        'created': [],\n        'model': [],\n        'object': [],\n        'message_content': [],\n        'message_role': [],\n        'finish_reason': [],\n        'index': [],\n        'completion_tokens': [],\n        'prompt_tokens': [],\n        'total_tokens': [],\n    }\n\n    last_translated_q = q_start - 1\n    try:\n        for question in range(q_start, q_fin+1):\n            response = gpt_trans(year, code, question, model)\n\n            data['year'].append(year)\n            data['code'].append(code)\n            data['question_no'].append(question)\n            data['id'].append(response['id'])\n            data['created'].append(response['created'])\n            data['model'].append(response['model'])\n            data['object'].append(response['object'])\n            data['message_content'].append(response['choices'][0]['message']['content'])\n            data['message_role'].append(response['choices'][0]['message']['role'])\n            data['finish_reason'].append(response['choices'][0]['finish_reason'])\n            data['index'].append(response['choices'][0]['index'])\n            data['completion_tokens'].append(response['usage']['completion_tokens'])\n            data['prompt_tokens'].append(response['usage']['prompt_tokens'])\n            data['total_tokens'].append(response['usage']['total_tokens'])\n\n            print(f'Question {question} has been translated.')\n            last_translated_q = question\n    except IndexError:\n        print(\"Question number out of range. Exporting the data up to the last valid question.\")\n    finally:\n        df = pd.DataFrame(data)\n        filename = f'{year}_{code}_{q_start}_{last_translated_q}_model{model}.csv'\n        df.to_csv(filename, index=False)\n        print(f'Questions {q_start} to {last_translated_q} have been translated and saved as {filename}.')\n        estimate_cost(df, model)\n\n        return df\n\n\ndef estimate_cost(df, model):\n    if model == 4:\n        cost_prompt = df['prompt_tokens'].sum() * 0.03 / 1000\n        cost_completion = df['completion_tokens'].sum() * 0.06 / 1000\n        total_cost = cost_prompt + cost_completion\n    elif model == 3.5:\n        total_cost = df['total_tokens'].sum() * 0.002 / 1000\n\n    print(f'Estimated API call cost: ${total_cost:.6f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T14:44:13.122390Z","iopub.execute_input":"2023-05-29T14:44:13.123425Z","iopub.status.idle":"2023-05-29T14:44:13.140898Z","shell.execute_reply.started":"2023-05-29T14:44:13.123365Z","shell.execute_reply":"2023-05-29T14:44:13.140074Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"gpt_trans_loop(112, 1302, 1, 100, 4)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpt_trans(112, 2301, 1, 3.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_q(112, 2301, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Answer Key for 112","metadata":{}},{"cell_type":"code","source":"ans_112_1301 = [\n    'A', 'D', 'A', 'C', 'A', 'D', 'D', 'A', 'A', 'C', \n    'C', 'D', 'C', 'D', 'B', 'B', 'C', 'A', 'C', 'D',\n    'A', 'D', 'D', 'C', 'D', 'C', 'D', 'C', 'D', 'C', \n    'C', 'A', 'D', 'A', 'C', 'A', 'B', 'C', 'A', 'B',\n    'B', 'C', 'A', 'B', 'B', 'B', 'D', 'B', 'A', 'A', \n    'A', 'D', 'D', 'A', 'C', 'A', 'D', 'A', 'B', 'D',\n    'A', 'D', 'A', 'D', 'C', ['B', 'D'], 'D', 'A', 'D', 'D',\n    'A', 'C', 'C', 'B', 'D', 'D', 'D', 'B', 'B', 'D',\n    'D', 'C', 'B', 'B', 'A', 'D', 'C', 'B', 'C', 'D', \n    'B', 'A', 'C', 'D', 'D', 'B', 'C', 'B', 'C', 'B'\n]\n\nans_112_1302 = [\n    'D', 'B', 'C', 'D', 'D', 'C', 'C', 'B', 'D', 'C',\n    'A', 'C', 'A', 'D', 'C', 'A', 'C', 'A', 'C', 'B',\n    'A', 'B', 'C', 'B', 'D', 'A', 'B', 'C', 'B', 'D',\n    'A', 'C', 'A', 'C', 'D', 'D', 'D', 'B', 'C', 'C',\n    'B', 'D', 'C', 'A', 'B', 'C', ['A', 'B', 'C', 'D'], 'C', 'C', 'B',\n    'D', 'B', 'D', 'B', 'A', 'B', 'C', 'A', 'A', 'A', \n    'A', 'D', 'C', 'D', 'C', 'A', 'D', 'D', 'B', 'B', \n    'B', 'C', 'A', 'A', 'D', 'D', 'D', 'A', 'C', 'D'\n]\n\nans_112_2301 = [\n    'B', 'B', 'D', 'C', 'D', 'B', 'C', 'B', 'B', 'C',\n    'B', 'A', 'B', 'C', 'B', 'A', 'D', 'A', 'B', 'C',\n    'B', 'C', 'A', 'D', 'A', 'D', 'D', 'B', 'C', 'A',\n    'B', 'A', 'D', 'C', 'C', ['A', 'B', 'C', 'D'], 'B', 'B', 'C', 'B',\n    'A', 'D', 'B', 'D', 'A', 'B', 'B', 'D', 'C', 'A',\n    'B', 'A', 'C', 'B', 'B', 'C', 'B', 'B', 'A', 'C',\n    'A', 'C', 'C', 'A', 'D', 'D', 'B', 'B', ['A', 'B', 'C', 'D'], 'D',\n    'A', 'A', 'A', 'A', 'A', 'A', 'D', 'C', 'D', 'D',\n    'A', 'D', 'C', 'B', 'B', 'D', 'A', 'C', 'A', 'C',\n    'A', 'D', 'C', 'D', 'B', 'B', 'D', 'D', 'D', 'B'\n]\n\nans_112_2302 = [\n    'B', 'A', 'C', 'D', 'B', 'B', 'C', 'D', 'B', 'B',\n    'A', 'D', 'A', 'A', 'C', 'B', 'D', 'B', 'C', 'B',\n    'B', 'C', 'D', 'D', 'B', 'A', 'C', 'C', 'B', 'B',\n    'A', 'A', 'D', 'B', 'D', 'B', 'D', 'C', 'B', 'B',\n    'B', 'B', 'C', 'A', 'B', 'C', 'A', 'D', 'D', 'B',\n    'C', 'D', 'A', 'B', 'D', 'B', 'B', 'C', 'C', 'C',\n    'C', 'C', 'D', 'C', 'C', 'A', 'C', 'C', 'A', 'B',\n    'D', 'D', 'C', 'C', 'B', 'A', 'C', 'C', 'C', 'D'\n]\n\nans_112_3302 = [\n    'B', 'B', 'C', 'C', 'B', 'A', 'D', 'A', 'D', 'B',\n    'D', 'D', 'D', 'D', 'A', 'B', 'C', 'B', 'B', 'A',\n    'C', 'D', 'A', 'C', 'B', 'B', 'D', 'B', 'A', 'D',\n    'D', 'D', 'A', 'B', 'D', 'D', 'C', 'B', 'A', 'B',\n    'D', 'D', 'B', 'B', 'B', 'A', 'C', 'A', 'D', 'C',\n    'C', 'C', 'D', 'C', 'B', 'D', 'B', 'A', 'C', 'A',\n    'A', 'A', 'C', 'C', 'A', 'A', 'A', 'A', 'B', 'C',\n    'D', 'C', 'B', 'B', 'B', 'D', 'B', 'A', 'B', 'C'\n]\n\nans_112_4302 = [\n    'A', 'D', 'B', 'B', 'C', 'C', 'D', 'C', 'D', 'A', \n    'A', 'A', 'B', 'D', 'D', 'B', 'B', 'C', 'A', 'A', \n    'B', 'A', 'B', 'D', 'A', 'C', 'D', 'B', 'B', 'C', \n    'A', 'D', 'A', 'A', 'B', 'D', 'A', 'C', 'A', 'A', \n    'A', 'D', 'C', 'D', 'C', 'D', 'C', 'A', 'C', 'A', \n    'A', 'B', 'D', 'B', 'D', 'B', 'D', 'A', 'A', 'B', \n    'A', 'C', 'A', 'B', 'D', 'C', 'D', 'C', 'C', 'D', \n    'C', 'A', 'C', 'B', 'D', 'D', 'C', 'C', 'D', 'A'\n]\n\n# Function to retrieve answer\ndef get_ans(year, code, question):\n    answers = globals()[f\"ans_{year}_{code}\"]\n    ans = answers[question - 1]  # -1 because list indexes start at 0\n    \n    # If the answer is a list (multiple correct answers)\n    if isinstance(ans, list):\n        # If all answers are correct\n        if set(ans) == set(['A', 'B', 'C', 'D']):\n            return '送分'\n        else:\n            # Return the multiple answers joined by \"or\"\n            return ' or '.join(ans)\n    else:\n        # If there's only one correct answer, return it as is\n        return ans","metadata":{"execution":{"iopub.status.busy":"2023-05-27T17:31:43.263666Z","iopub.execute_input":"2023-05-27T17:31:43.264095Z","iopub.status.idle":"2023-05-27T17:31:43.298285Z","shell.execute_reply.started":"2023-05-27T17:31:43.264064Z","shell.execute_reply":"2023-05-27T17:31:43.297125Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_ans(112,1302, 48)","metadata":{"execution":{"iopub.status.busy":"2023-05-27T17:32:31.414309Z","iopub.execute_input":"2023-05-27T17:32:31.414741Z","iopub.status.idle":"2023-05-27T17:32:31.422269Z","shell.execute_reply.started":"2023-05-27T17:32:31.414706Z","shell.execute_reply":"2023-05-27T17:32:31.420968Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code for Q bank parsing","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\n\ntext = input()\n\nyear_pattern = re.compile(r\"(\\d+)+年\")\nyear = year_pattern.search(text)\nif year:\n    year = year.group(1)\n\nsubject_code_pattern = re.compile(r\"代 號:(\\d+)\")\nsubject_code_match = subject_code_pattern.search(text)\nif subject_code_match:\n    subject_code = subject_code_match.group(1)\n\nquestion_list = []\nnext_question_number = 1\nfor part in re.split(r\"(\\d+)\\.\", text):\n    try:\n        current_number = int(part.strip())\n        if current_number == next_question_number:\n            question_list.append({\n                'Year': year,\n                'Subject Code': subject_code,\n                'Question Number': current_number,\n                'Question and Options': '',\n            })\n            next_question_number += 1\n        else:\n            if question_list:\n                question_list[-1]['Question and Options'] += part.strip()\n    except ValueError:\n        if question_list: \n            question_list[-1]['Question and Options'] += part.strip()\n\ndf = pd.DataFrame(question_list)\ndisplay(df)\n\nfile_name = f\"{year}_{subject_code}.csv\"\ndf.to_csv(file_name, index=False)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]}]}